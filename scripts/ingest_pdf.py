import os
from dotenv import load_dotenv
# ç¢ºä¿é€™äº›è·¯å¾‘æ­£ç¢º
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_postgres.vectorstores import PGVector

load_dotenv()

def run_ingest():
    # ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦å­˜åœ¨
    pdf_path = "data/bp.pdf"
    if not os.path.exists(pdf_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {pdf_path}ï¼Œè«‹ç¢ºèªæª”æ¡ˆå·²æ”¾å…¥ data è³‡æ–™å¤¾")
        return

    try:
        print(f"ğŸ“‚ æ­£åœ¨è®€å–è¡€å£“è¨ˆèªªæ˜æ›¸ ({pdf_path})...")
        loader = PyPDFLoader(pdf_path)
        raw_docs = loader.load()

        print("âœ‚ï¸ æ­£åœ¨é€²è¡Œç²¾ç´°åˆ‡ç‰‡...")
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        docs = splitter.split_documents(raw_docs)

        print(f"ğŸ§  æ­£åœ¨ç”Ÿæˆå‘é‡ä¸¦å­˜å…¥ pgvector... (ç¸½å…± {len(docs)} å€‹æ®µè½)")
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004", 
            google_api_key=os.getenv("GEMINI_API_KEY")
        )

        # å¯«å…¥è³‡æ–™åº«
        PGVector.from_documents(
            embedding=embeddings,
            documents=docs,
            collection_name="bp_docs_gemini",
            connection=os.getenv("DATABASE_URL"),
            use_jsonb=True,
        )

        print("âœ… æˆåŠŸï¼Python ç‰ˆè¡€å£“è¨ˆçŸ¥è­˜åº«å·²å»ºç«‹ã€‚")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    run_ingest()