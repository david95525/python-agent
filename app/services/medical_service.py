import os
from typing import List, Dict, Annotated, TypedDict, Literal
import operator
import json
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

from app.services.base import BaseAgent
from app.services.tools.system_tools import load_specialized_skill
from app.services.tools.medical_tools import search_device_manual, get_user_health_data

from app.utils.logger import setup_logger

logger = setup_logger("AgentService")


# å®šç¾© Graph ç‹€æ…‹
class AgentState(TypedDict):
    user_id: str
    input_message: str
    messages: Annotated[List[BaseMessage], operator.add]  # ç´¯åŠ å°è©±æ­·å²
    intent: Literal["device", "health", "general"]  # è·¯ç”±æ„åœ–
    is_emergency: bool  # æ–°å¢ï¼šç”¨æ–¼åˆ¤æ–·æ˜¯å¦è§¸ç™¼ç·Šæ€¥ç‹€æ…‹
    context_data: str  # å·¥å…·æŠ“å–çš„åŸå§‹æ•¸æ“š
    final_response: str  # æœ€çµ‚ç”¢å‡ºçš„å›è¦†


class MedicalAgentService(BaseAgent):

    def __init__(self):
        # è¼‰å…¥è¨»å†Šè¡¨ (Registry)
        self.skills_registry = self._load_registry()
        # æ§‹å»ºç”Ÿç”¢ç·š (Graph)
        self.workflow = self._build_workflow()
        self.app = self.workflow.compile()

        # ç°¡å–®è¨˜æ†¶é«”
        self.chat_history_map: Dict[str, List[BaseMessage]] = {}

    def _load_registry(self) -> dict:
        """è¼‰å…¥æŠ€èƒ½åœ°åœ–"""
        path = os.path.join("skills", "registry.json")
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(
                    f"[System] æŠ€èƒ½è¨»å†Šè¡¨è¼‰å…¥æˆåŠŸï¼Œå…± {len(data.get('skills', []))}å€‹å°ˆæ¥­æ¨¡çµ„")
                return data
        except Exception as e:
            logger.error(f"[System] ç„¡æ³•è¼‰å…¥è¨»å†Šè¡¨ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–æ ¼å¼: {e}")
            return {"skills": []}

    def _get_manifest_for_prompt(self) -> str:
        """å°‡è¨»å†Šè¡¨è½‰æ›ç‚º Router çœ‹å¾—æ‡‚çš„æ–‡å­—"""
        manifest = []
        for skill in self.skills_registry.get("skills", []):
            manifest.append(f"- '{skill['id']}': {skill['description']}")
        manifest.append("- 'general': è™•ç†æ—¥å¸¸å¯’æš„ã€å¿ƒæƒ…åˆ†äº«æˆ–éä¸Šè¿°å°ˆæ¥­é ˜åŸŸçš„å•é¡Œã€‚")
        return "\n".join(manifest)

    def _build_workflow(self):
        graph = StateGraph(AgentState)

        # å®šç¾©ç¯€é» (Nodes)
        graph.add_node("router", self.node_router)
        graph.add_node("device_expert", self.node_device_expert)
        graph.add_node("health_analyst", self.node_health_analyst)
        graph.add_node("emergency_advice", self.node_emergency_advice)
        graph.add_node("general_assistant", self.node_general_assistant)

        # å®šç¾©é‚Šèˆ‡æ¢ä»¶ (Edges & Conditional Edges)
        graph.add_edge(START, "router")

        # æ ¹æ“š router çš„æ„åœ–æ±ºå®šå»å‘
        graph.add_conditional_edges(
            "router", lambda state: state["intent"], {
                "device": "device_expert",
                "health": "health_analyst",
                "general": "general_assistant"
            })
        # å¥åº·åˆ†æå®Œå¾Œï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦ã€Œç·Šæ€¥å»ºè­°ã€
        graph.add_conditional_edges(
            "health_analyst", lambda state: "emergency"
            if state.get("is_emergency") else "normal", {
                "emergency": "emergency_advice",
                "normal": END
            })
        # å°ˆå®¶è™•ç†å®Œå¾Œå…¨éƒ¨æŒ‡å‘çµæŸ
        graph.add_edge("device_expert", END)
        graph.add_edge("emergency_advice", END)
        graph.add_edge("general_assistant", END)

        return graph

    async def node_router(self, state: AgentState):
        """æ„åœ–è·¯ç”±ï¼šæ”¹ç‚ºéåŒæ­¥ä¸¦å¼·åŒ–ç©©å®šæ€§"""
        # å‹•æ…‹ç”Ÿæˆ Manifest
        manifest = self._get_manifest_for_prompt()
        prompt = ("ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä»»å‹™åˆ†ç™¼ä¸­å¿ƒã€‚è«‹æ ¹æ“šä»¥ä¸‹æŠ€èƒ½æ¨¡çµ„çš„æè¿°ï¼Œåˆ¤æ–·ç”¨æˆ¶è¨Šæ¯æœ€é©åˆäº¤çµ¦å“ªä½å°ˆå®¶è™•ç†ï¼š\n\n"
                  f"{manifest}\n\n"
                  f"ç”¨æˆ¶è¨Šæ¯ï¼š{state['input_message']}\n\n"
                  "ã€æŒ‡ä»¤ã€‘è«‹åƒ…å›å‚³ä¸Šè¿°æ¸…å–®ä¸­å°æ‡‰çš„ã€Œæ¨™ç±¤åç¨±ã€ï¼ˆIDï¼‰ï¼Œè‹¥ä¸å±¬æ–¼ä»»ä½•å°ˆæ¥­é ˜åŸŸå‰‡å›å‚³ 'general'ã€‚"
                  "åš´ç¦å›å‚³æ¨™ç±¤ä»¥å¤–çš„ä»»ä½•è§£é‡‹æˆ–æ¨™é»ç¬¦è™Ÿã€‚")
        res = await self.llm.ainvoke(prompt)
        intent_text = res.content.strip().lower()
        raw_intent = intent_text.replace(".", "").replace("'", "")
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨æ–¼è¨»å†Šè¡¨ä¸­ï¼Œè‹¥ç„¡å‰‡æ­¸é¡ç‚º general
        all_ids = [s["id"] for s in self.skills_registry.get("skills", [])]
        final_intent = "general"
        for valid_id in all_ids:
            if valid_id in raw_intent:
                final_intent = valid_id
                break
        logger.info(
            f"[Router Decision] è­˜åˆ¥æ„åœ–: {final_intent} (åŸå§‹å›è¦†: {intent_text})")
        return {"intent": final_intent}

    async def node_device_expert(self, state: AgentState):
        """ç¡¬é«”å°ˆå®¶ç¯€é»ï¼šå°ˆæ³¨æ–¼ RAG æª¢ç´¢"""
        # å‹•æ…‹åŠ è¼‰Skills
        skill_content = load_specialized_skill.invoke(
            {"skill_name": "device_expert"})
        # åŸ·è¡Œ RAG
        raw_info = await search_device_manual.ainvoke(
            {"query": state["input_message"]})
        logger.info(f"[RAG] æª¢ç´¢å®Œæˆï¼Œç²å–è³‡æ–™é•·åº¦: {len(raw_info)} å­—å…ƒ")
        prompt = (f"### å°ˆæ¥­åŸ·è¡Œç´°å‰‡ ###\n{skill_content}\n\n"
                  f"### æª¢ç´¢åˆ°çš„èªªæ˜æ›¸è³‡è¨Š ###\n{raw_info}\n\n"
                  f"è«‹æ ¹æ“šä¸Šè¿°è¦ç¯„å›ç­”ç”¨æˆ¶ï¼š{state['input_message']}")
        res = await self.llm.ainvoke(prompt)
        return {"final_response": res.content}

    async def node_health_analyst(self, state: AgentState):
        """å¥åº·åˆ†æå¸«ç¯€é»ï¼šå°ˆæ³¨æ–¼æ•¸æ“šè™•ç†"""
        # å‹•æ…‹åŠ è¼‰Skills
        skill_info = load_specialized_skill.invoke(
            {"skill_name": "health_analyst"})
        # èª¿ç”¨å·¥å…·ç²å–è¡€å£“æ•¸æ“š
        raw_data = get_user_health_data.invoke({"user_id": state["user_id"]})

        prompt = (f"### å°ˆæ¥­è¦ç¯„ ###\n{skill_info}\n\n"
                  f"### çœŸå¯¦æ•¸æ“š ###\n{raw_data}\n\n"
                  f"### ç”¨æˆ¶ç•¶å‰æè¿° ###\n{state['input_message']}\n\n"
                  "1. è«‹çµåˆæ­·å²æ•¸æ“šèˆ‡ã€ç”¨æˆ¶ç•¶å‰æè¿°çš„æ•¸å€¼ã€é€²è¡Œç¶œåˆåˆ†æã€‚\n"
                  "2. è«‹æ ¹æ“šè¦ç¯„åˆ†ææ•¸æ“šã€‚è‹¥å‡ºç¾ä»»ä½•ä¸€é …ã€ç•°å¸¸ã€(BP, SpO2, Temp)ï¼Œ"
                  "è«‹åœ¨æ–‡æœ«æ¨™è¨» [EMERGENCY]ï¼Œå¦å‰‡æ¨™è¨» [NORMAL]ã€‚")

        res = await self.llm.ainvoke(prompt)

        data_list = json.loads(raw_data).get("history", [])
        can_visualize = len(data_list) >= 5
        # æ–°å¢ï¼šè¨˜éŒ„ LLM åŸå§‹åˆ¤æ–·
        logger.debug(f"[LLM Raw] åˆ†æå¸«å›è¦†åŸæ–‡: {res.content}")
        is_emergency = "[EMERGENCY]" in res.content
        logger.info(f"[Risk Analysis] æ˜¯å¦è§¸ç™¼ç·Šæ€¥ç‹€æ…‹: {is_emergency}")
        clean_content = res.content.replace("[EMERGENCY]",
                                            "").replace("[NORMAL]", "")
        if can_visualize:
            clean_content += ("\n\nğŸ’¡ **ç³»çµ±åµæ¸¬åˆ°æ•¸æ“šé‡å……è¶³ï¼Œéœ€è¦æˆ‘ç‚ºæ‚¨ç¹ªè£½è¶¨å‹¢åˆ†æåœ–è¡¨å—ï¼Ÿ**")
        return {"final_response": clean_content, "is_emergency": is_emergency}

    async def node_emergency_advice(self, state: AgentState):
        """ç·Šæ€¥å»ºè­°ç¯€é»ï¼šè‡¨åºŠæŒ‡å¼•æ¨¡å¼"""
        prompt = ("### è‡¨åºŠé¢¨éšªè­¦ç¤º ###\n"
                  "ç•¶å‰æª¢æ¸¬åˆ°ç”¨æˆ¶è¡€å£“æ•¸æ“šå·²é”è‡¨åºŠè­¦æˆ’æ°´ä½ã€‚\n"
                  "è«‹æä¾›æ¨™æº–åŒ–çš„é†«å­¸å»ºè­°ï¼š\n"
                  "1. å»ºè­°ç”¨æˆ¶ä¿æŒå¹³éœï¼Œéœå 15 åˆ†é˜å¾Œé‡æ–°æ¸¬é‡ã€‚\n"
                  "2. è‹¥ä¼´éš¨é ­ç—›ã€èƒ¸ç—›ç­‰ç—‡ç‹€ï¼Œå»ºè­°ç«‹å³å°‹æ±‚å°ˆæ¥­é†«ç™‚å”åŠ©æˆ–æ’¥æ‰“ç·Šæ€¥é›»è©±ã€‚")
        res = await self.llm.ainvoke(prompt)
        combined = f"{state['final_response']}\n\n--- âš ï¸ ç³»çµ±è‡¨åºŠå»ºè­° ---\n{res.content}"

        return {"final_response": combined}

    async def node_general_assistant(self, state: AgentState):
        """é€šç”¨ç¯€é»ï¼šè™•ç†ç¯„ç–‡å¤–å•é¡Œ"""
        res = await self.llm.ainvoke(
            f"ä½ æ˜¯ä¸€ä½ç¦®è²Œçš„åŠ©æ‰‹ï¼Œè«‹å‘ŠçŸ¥ç”¨æˆ¶ä½ å°ˆæ³¨æ–¼å¥åº·æ•¸æ“šåˆ†ææˆ–è¨­å‚™èªªæ˜ï¼Œç„¡æ³•å›ç­”ä»¥ä¸‹å•é¡Œï¼š{state['input_message']}"
        )
        logger.info(
            f"[Router Decision] æ„åœ–è¾¨è­˜çµæœ: {state['intent']} (åŸå§‹è¨Šæ¯: {state['input_message']})"
        )
        return {"final_response": res.content}

    # --- API é€²å…¥é» ---
    async def handle_chat(self, user_id: str, message: str) -> str:
        # å–å¾—æ­·å²ç´€éŒ„
        history = self.chat_history_map.get(user_id, [])
        initial_state = {
            "user_id": user_id,
            "input_message": message,
            "messages": history + [HumanMessage(content=message)],
        }
        try:
            # å•Ÿå‹• LangGraph ç”Ÿç”¢ç·š
            final_state = await self.app.ainvoke(initial_state)
            final_text = final_state["final_response"]
            mermaid_graph = self.app.get_graph().draw_mermaid()
            if final_state.get("is_emergency"):
                mermaid_graph += "\nclass emergency_advice activeEmergencyNode"
            # æ ¼å¼åŒ–è¼¸å‡ºï¼ˆåŠ ä¸Šè¿½è¹¤è³‡è¨Šï¼Œæ–¹ä¾¿ç ”ç©¶åˆ†æï¼‰
            logger.info(
                f"\n\n-Agent è·¯ç”±è¿½è¹¤-\næ„åœ–ï¼š{final_state.get('intent')}\nç¯€é»è·¯å¾‘ï¼šRouter -> {final_state.get('intent')}_expert"
            )
            # æ›´æ–°è¨˜æ†¶é«”
            self._update_history(user_id, message, final_text)
            # æ•´ç†å›å‚³çµæ§‹
            response_data = {
                "text": final_text,
                "graph": mermaid_graph,
                "intent": final_state.get("intent", "general"),
            }
            logger.info(f"[Response] å›å‚³çµæœ: {response_data}")
            return response_data

        except Exception as e:
            logger.error(f"Graph Execution Error: {e}", exc_info=True)
            return "åˆ†æéç¨‹å‡ºç¾ç•°å¸¸ï¼Œè«‹æª¢æŸ¥è¨­å‚™é€£ç·šã€‚"

    def _update_history(self, user_id: str, user_msg: str, ai_msg: str):
        history = self.chat_history_map.get(user_id, [])
        history.append(HumanMessage(content=user_msg))
        history.append(AIMessage(content=ai_msg))
        self.chat_history_map[user_id] = history[-10:]
        # æ–°å¢ï¼šç›£æ§è¨˜æ†¶é«”å¤§å°
        logger.info(
            f"[Memory] User: {user_id}, ç•¶å‰å°è©±æ­·å²é•·åº¦: {len(self.chat_history_map[user_id])}"
        )


def save_graph_image(agent_service):
    try:
        # å–å¾—ç·¨è­¯å¾Œçš„åœ–çµæ§‹ï¼Œä¸¦è½‰æ›ç‚º Mermaid æ ¼å¼çš„ PNG
        graph_image = agent_service.app.get_graph().draw_mermaid_png()

        with open("agent_workflow.png", "wb") as f:
            f.write(graph_image)
        logger.info("æµç¨‹åœ–å·²æˆåŠŸå„²å­˜ç‚º agent_workflow.png")
    except Exception as e:
        logger.error(f"ç„¡æ³•ç”¢ç”Ÿåœ–ç‰‡ï¼Œè«‹ç¢ºä¿å®‰è£äº†å¿…è¦å¥—ä»¶: {e}")
