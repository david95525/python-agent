import os
import re
from typing import List, Dict, Annotated, TypedDict, Literal
import operator
import json
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

from app.services.base import BaseAgent
from app.services.tools.system_tools import load_specialized_skill
from app.services.tools.medical_tools import (
    search_device_manual,
    get_user_health_data,
    plot_health_chart,
)

from app.utils.logger import setup_logger

logger = setup_logger("AgentService")


# å®šç¾© Graph ç‹€æ…‹
class AgentState(TypedDict):
    user_id: str
    input_message: str
    messages: Annotated[List[BaseMessage], operator.add]  # ç´¯åŠ å°è©±æ­·å²
    intent: Literal["device", "health", "general", "visualizer"]  # è·¯ç”±æ„åœ–
    is_emergency: bool  # æ–°å¢ï¼šç”¨æ–¼åˆ¤æ–·æ˜¯å¦è§¸ç™¼ç·Šæ€¥ç‹€æ…‹
    context_data: str  # å·¥å…·æŠ“å–çš„åŸå§‹æ•¸æ“š
    final_response: str  # æœ€çµ‚ç”¢å‡ºçš„å›è¦†


class MedicalAgentService(BaseAgent):

    def __init__(self):
        super().__init__("MedicalService")
        # è¼‰å…¥è¨»å†Šè¡¨ (Registry)
        self.skills_registry = self._load_registry()
        # æ§‹å»ºç”Ÿç”¢ç·š (Graph)
        self.workflow = self._build_workflow()
        self.app = self.workflow.compile()

        # ç°¡å–®è¨˜æ†¶é«”
        self.chat_history_map: Dict[str, List[BaseMessage]] = {}

    def _load_registry(self) -> dict:
        """è¼‰å…¥æŠ€èƒ½åœ°åœ–"""
        path = os.path.join("skills", "registry.json")
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(
                    f"[System] æŠ€èƒ½è¨»å†Šè¡¨è¼‰å…¥æˆåŠŸï¼Œå…± {len(data.get('skills', []))}å€‹å°ˆæ¥­æ¨¡çµ„"
                )
                return data
        except Exception as e:
            logger.error(f"[System] ç„¡æ³•è¼‰å…¥è¨»å†Šè¡¨ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–æ ¼å¼: {e}")
            return {"skills": []}

    def _get_manifest_for_prompt(self) -> str:
        """å°‡è¨»å†Šè¡¨è½‰æ›ç‚º Router çœ‹å¾—æ‡‚çš„æ–‡å­—"""
        manifest = []
        for skill in self.skills_registry.get("skills", []):
            manifest.append(f"- '{skill['id']}': {skill['description']}")
        manifest.append("- 'general': è™•ç†æ—¥å¸¸å¯’æš„ã€å¿ƒæƒ…åˆ†äº«æˆ–éä¸Šè¿°å°ˆæ¥­é ˜åŸŸçš„å•é¡Œã€‚")
        return "\n".join(manifest)

    def _build_workflow(self):
        graph = StateGraph(AgentState)

        # å®šç¾©ç¯€é» (ä¿æŒä¸è®Š)
        graph.add_node("router", self.node_router)
        graph.add_node("device_expert", self.node_device_expert)
        graph.add_node("health_analyst", self.node_health_analyst)
        graph.add_node("emergency_advice", self.node_emergency_advice)
        graph.add_node("general_assistant", self.node_general_assistant)
        graph.add_node("visualizer", self.node_visualizer)

        graph.add_edge(START, "router")

        # æ ¹æ“š router çš„æ„åœ–æ±ºå®šå»å‘
        graph.add_conditional_edges(
            "router",
            lambda state: state["intent"],
            {
                "device_expert": "device_expert",
                "health_analyst": "health_analyst",
                "visualizer": "visualizer",
                "general": "general_assistant",
            },
        )

        def route_after_analysis(state: AgentState):
            # å„ªå…ˆæª¢æŸ¥ç·Šæ€¥ç‹€æ…‹
            if state.get("is_emergency"):
                return "emergency"
            # æª¢æŸ¥ä½¿ç”¨è€…åŸå§‹è¼¸å…¥æ˜¯å¦æœ‰ç¹ªåœ–é—œéµå­—
            keywords = ["åœ–", "ç•«", "chart", "plot", "visualize"]
            if any(k in state["input_message"].lower() for k in keywords):
                return "visualize"
            return "end"

        # å¥åº·åˆ†æå®Œå¾Œï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦ã€Œç·Šæ€¥å»ºè­°ã€
        graph.add_conditional_edges(
            "health_analyst",
            route_after_analysis,
            {"emergency": "emergency_advice", "visualize": "visualizer", "end": END},
        )
        graph.add_edge("device_expert", END)
        graph.add_edge("emergency_advice", END)
        graph.add_edge("general_assistant", END)
        graph.add_edge("visualizer", END)

        return graph

    async def node_router(self, state: AgentState):
        """æ„åœ–è·¯ç”±ï¼šåŠ å…¥ä¸Šä¸‹æ–‡åƒè€ƒï¼Œé˜²æ­¢ç°¡çŸ­å›è¦†è¢«èª¤åˆ¤"""
        manifest = self._get_manifest_for_prompt()
        # å–æœ€å¾Œä¸€å‰‡ AI çš„è¨Šæ¯ï¼Œç”¨ä»¥åˆ¤æ–·ä¸Šä¸‹æ–‡
        last_ai_message = ""
        if state.get("messages"):
            for m in reversed(state["messages"]):
                if isinstance(m, AIMessage):
                    last_ai_message = m.content
                    break
        # [ç¬¬ä¸€å±¤ä¿éšª] ç¡¬ç·¨ç¢¼è¦å‰‡ï¼šå¦‚æœ AI å‰›å•å®Œè¦ä¸è¦ç•«åœ–ï¼Œä¸”ç”¨æˆ¶èªªã€Œå¥½ã€
        confirm_keywords = ["å¥½", "è¦", "ç•«", "ok", "yes", "ç¢ºèª", "ç•«å§", "é¡¯ç¤º"]
        is_asking_to_plot = "ç¹ªè£½è¶¨å‹¢åˆ†æåœ–è¡¨å—" in last_ai_message
        user_input_clean = state["input_message"].strip().lower()

        if is_asking_to_plot and any(k in user_input_clean for k in confirm_keywords):
            logger.info("[Router Decision] è§¸ç™¼ä¸Šä¸‹æ–‡æ””æˆªè¦å‰‡: å°å‘ visualizer")
            return {"intent": "visualizer"}
        # 3. [ç¬¬äºŒå±¤ä¿éšª] LLM åˆ¤æ–·
        prompt = (
            "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä»»å‹™åˆ†ç™¼ä¸­å¿ƒã€‚è«‹æ ¹æ“šå°è©±æ­·å²èˆ‡ç”¨æˆ¶è¨Šæ¯åˆ¤æ–·æ„åœ–ï¼š\n\n"
            f"ã€æŠ€èƒ½æ¸…å–®ã€‘\n{manifest}\n"
            "- 'visualizer': ç•¶ç”¨æˆ¶æ˜ç¢ºè¦æ±‚ç¹ªåœ–ï¼Œæˆ–åŒæ„ AI ä¹‹å‰çš„ç¹ªåœ–å»ºè­°æ™‚ä½¿ç”¨ã€‚\n\n"  # å¼·åˆ¶åŠ å…¥ visualizer èªªæ˜
            f"ã€æœ€å¾Œä¸€å‰‡ AI å›è¦†ã€‘\n{last_ai_message}\n\n"
            f"ã€ç”¨æˆ¶ç•¶å‰è¨Šæ¯ã€‘\n{state['input_message']}\n\n"
            "ã€é—œéµåˆ¤å®šè¦å‰‡ã€‘\n"
            "1. å¦‚æœ AI ä¸Šä¸€å‰‡è¨Šæ¯è©¢å•äº†ã€æ˜¯å¦ç¹ªè£½åœ–è¡¨ã€ï¼Œä¸”ç”¨æˆ¶å›ç­”è‚¯å®šï¼Œè«‹å‹™å¿…å›å‚³ 'visualizer'ã€‚\n"
            "2. å¦‚æœç”¨æˆ¶è©¢å•è¨­å‚™æ•…éšœã€èªªæ˜æ›¸è³‡è¨Šï¼Œè«‹å›å‚³ 'device_expert'ã€‚\n"
            "3. å¦‚æœç”¨æˆ¶æä¾›æ•¸æ“šè¦æ±‚åˆ†æï¼Œè«‹å›å‚³ 'health_analyst'ã€‚\n"
            "4. å¦å‰‡å›å‚³ 'general'ã€‚\n\n"
            "ã€æŒ‡ä»¤ã€‘åƒ…å›å‚³æ¨™ç±¤åç¨± IDï¼Œåš´ç¦ä»»ä½•è§£é‡‹ã€‚"
        )

        res = await self.llm.ainvoke(prompt)
        intent_text = res.content.strip().lower()
        raw_intent = intent_text.replace(".", "").replace("'", "")

        # é©—è­‰ ID åˆæ³•æ€§ (åŒ…å«æ‰‹å‹•åŠ å…¥çš„ visualizer)
        valid_ids = [s["id"] for s in self.skills_registry.get("skills", [])]
        valid_ids.extend(["visualizer", "general"])

        final_intent = "general"
        # ä¾ç…§é•·åº¦æ’åºï¼Œå„ªå…ˆåŒ¹é…è¼ƒé•·çš„ ID (ä¾‹å¦‚ health_analyst å„ªæ–¼ health)
        sorted_ids = sorted(valid_ids, key=len, reverse=True)

        for vid in sorted_ids:
            if vid.lower() in raw_intent:
                final_intent = vid
                break  # <--- åªæœ‰åŒ¹é…æˆåŠŸæ‰è·³å‡ºè¿´åœˆ

        logger.info(
            f"[Router Decision] è­˜åˆ¥æ„åœ–: {final_intent} (åŸå§‹å›è¦†: {intent_text})"
        )
        return {"intent": final_intent}

    async def node_device_expert(self, state: AgentState):
        """ç¡¬é«”å°ˆå®¶ç¯€é»ï¼šå°ˆæ³¨æ–¼ RAG æª¢ç´¢"""
        # å‹•æ…‹åŠ è¼‰Skills
        skill_content = load_specialized_skill.invoke({"skill_name": "device_expert"})
        # åŸ·è¡Œ RAG
        raw_info = await search_device_manual.ainvoke({"query": state["input_message"]})
        logger.info(f"[RAG] æª¢ç´¢å®Œæˆï¼Œç²å–è³‡æ–™é•·åº¦: {len(raw_info)} å­—å…ƒ")
        prompt = (
            f"### å°ˆæ¥­åŸ·è¡Œç´°å‰‡ ###\n{skill_content}\n\n"
            f"### æª¢ç´¢åˆ°çš„èªªæ˜æ›¸è³‡è¨Š ###\n{raw_info}\n\n"
            f"è«‹æ ¹æ“šä¸Šè¿°è¦ç¯„å›ç­”ç”¨æˆ¶ï¼š{state['input_message']}"
        )
        res = await self.llm.ainvoke(prompt)
        return {"final_response": res.content}

    async def node_health_analyst(self, state: AgentState):
        """å¥åº·åˆ†æå¸«ç¯€é»ï¼šå°ˆæ³¨æ–¼æ•¸æ“šè™•ç†"""
        # å‹•æ…‹åŠ è¼‰Skills
        skill_info = load_specialized_skill.invoke({"skill_name": "health_analyst"})
        # èª¿ç”¨å·¥å…·ç²å–è¡€å£“æ•¸æ“š
        raw_data = get_user_health_data.invoke({"user_id": state["user_id"]})

        prompt = (
            f"### å°ˆæ¥­è¦ç¯„ ###\n{skill_info}\n\n"
            f"### çœŸå¯¦æ•¸æ“š ###\n{raw_data}\n\n"
            f"### ç”¨æˆ¶ç•¶å‰æè¿° ###\n{state['input_message']}\n\n"
            "1. è«‹çµåˆæ­·å²æ•¸æ“šèˆ‡ã€ç”¨æˆ¶ç•¶å‰æè¿°çš„æ•¸å€¼ã€é€²è¡Œç¶œåˆåˆ†æã€‚\n"
            "2. è«‹æ ¹æ“šè¦ç¯„åˆ†ææ•¸æ“šã€‚è‹¥å‡ºç¾ä»»ä½•ä¸€é …ã€ç•°å¸¸ã€(BP, SpO2, Temp)ï¼Œ"
            "è«‹åœ¨æ–‡æœ«æ¨™è¨» [EMERGENCY]ï¼Œå¦å‰‡æ¨™è¨» [NORMAL]ã€‚"
        )

        res = await self.llm.ainvoke(prompt)

        data_list = json.loads(raw_data).get("history", [])
        can_visualize = len(data_list) >= 5
        # æ–°å¢ï¼šè¨˜éŒ„ LLM åŸå§‹åˆ¤æ–·
        logger.debug(f"[LLM Raw] åˆ†æå¸«å›è¦†åŸæ–‡: {res.content}")
        is_emergency = "[EMERGENCY]" in res.content
        logger.info(f"[Risk Analysis] æ˜¯å¦è§¸ç™¼ç·Šæ€¥ç‹€æ…‹: {is_emergency}")
        clean_content = res.content.replace("[EMERGENCY]", "").replace("[NORMAL]", "")
        if can_visualize:
            clean_content += (
                "\n\nğŸ’¡ **ç³»çµ±åµæ¸¬åˆ°æ•¸æ“šé‡å……è¶³ï¼Œéœ€è¦æˆ‘ç‚ºæ‚¨ç¹ªè£½è¶¨å‹¢åˆ†æåœ–è¡¨å—ï¼Ÿ**"
            )
        return {
            "final_response": clean_content,
            "is_emergency": is_emergency,
            "context_data": raw_data,
        }

    async def node_emergency_advice(self, state: AgentState):
        """ç·Šæ€¥å»ºè­°ç¯€é»ï¼šè‡¨åºŠæŒ‡å¼•æ¨¡å¼"""
        prompt = (
            "### è‡¨åºŠé¢¨éšªè­¦ç¤º ###\n"
            "ç•¶å‰æª¢æ¸¬åˆ°ç”¨æˆ¶è¡€å£“æ•¸æ“šå·²é”è‡¨åºŠè­¦æˆ’æ°´ä½ã€‚\n"
            "è«‹æä¾›æ¨™æº–åŒ–çš„é†«å­¸å»ºè­°ï¼š\n"
            "1. å»ºè­°ç”¨æˆ¶ä¿æŒå¹³éœï¼Œéœå 15 åˆ†é˜å¾Œé‡æ–°æ¸¬é‡ã€‚\n"
            "2. è‹¥ä¼´éš¨é ­ç—›ã€èƒ¸ç—›ç­‰ç—‡ç‹€ï¼Œå»ºè­°ç«‹å³å°‹æ±‚å°ˆæ¥­é†«ç™‚å”åŠ©æˆ–æ’¥æ‰“ç·Šæ€¥é›»è©±ã€‚"
        )
        res = await self.llm.ainvoke(prompt)
        combined = f"{state['final_response']}\n\n--- âš ï¸ ç³»çµ±è‡¨åºŠå»ºè­° ---\n{res.content}"

        return {"final_response": combined}

    async def node_visualizer(self, state: AgentState):
        """ç¹ªåœ–å°ˆå®¶ç¯€é»ï¼šèª¿ç”¨å·¥å…·ç”¢å‡ºåœ–è¡¨"""
        # å–å¾—æ•¸æ“šï¼ˆå¾ node_health_analyst ä¹‹å‰å­˜å¥½çš„ raw_data æˆ–é‡æ–°ç²å–ï¼‰
        raw_data = state.get("context_data")
        if not raw_data:
            raw_data = get_user_health_data.invoke({"user_id": state["user_id"]})
            logger.warning(
                f"[Visualizer] State ä¸­ç„¡æ•¸æ“šï¼Œå·²é‡æ–°æŠ“å–ç”¨æˆ¶ {state['user_id']} æ•¸æ“š"
            )

        # è®“ LLM æ±ºå®šåƒæ•¸ï¼ˆä¾‹å¦‚åˆ¤æ–·ç”¨æˆ¶è¦ bar é‚„æ˜¯ lineï¼‰
        visualizer_instruction = (
            "ä½ ç¾åœ¨æ˜¯ã€æ•¸æ“šè¦–è¦ºåŒ–å°ˆå®¶ã€ã€‚è«‹æ ¹æ“šç”¨æˆ¶è¦æ±‚ï¼Œå¾ ['line', 'bar', 'scatter'] ä¸­æŒ‘é¸æœ€é©åˆçš„ chart_typeã€‚\n"
            "- è¶¨å‹¢/éš¨æ„è¦æ±‚ï¼šline\n"
            "- å°æ¯”/æ¯”è¼ƒæ•¸å€¼ï¼šbar\n"
            "- é›¢æ•£ç¨‹åº¦/å¤§é‡é»ï¼šscatter\n"
            "è«‹åƒ…å›å‚³å·¥å…·èª¿ç”¨æ‰€éœ€çš„åƒæ•¸ã€‚"
        )
        type_res = await self.llm.ainvoke(visualizer_instruction)
        # èª¿ç”¨å·¥å…·
        selected_type = "line"
        content = type_res.content.lower()
        if "bar" in content or "é•·æ¢" in content:
            selected_type = "bar"
        if "scatter" in content or "æ•£ä½ˆ" in content:
            selected_type = "scatter"
        # åŸ·è¡Œç¹ªåœ–å·¥å…·
        chart_base64 = plot_health_chart.invoke(
            {
                "data": raw_data,
                "title": f"ç”¨æˆ¶ {state['user_id']} å¥åº·æ•¸æ“šè¶¨å‹¢",
                "chart_type": selected_type,
            }
        )
        # å°è£å›å‚³
        final_text = f"ğŸ“Š **å·²ç‚ºæ‚¨ç”Ÿæˆ{selected_type}è¶¨å‹¢åœ–è¡¨**ï¼š\n\n![Health Chart]({chart_base64})"

        return {"final_response": final_text}

    async def node_general_assistant(self, state: AgentState):
        """é€šç”¨ç¯€é»ï¼šè™•ç†ç¯„ç–‡å¤–å•é¡Œ"""
        res = await self.llm.ainvoke(
            f"ä½ æ˜¯ä¸€ä½ç¦®è²Œçš„åŠ©æ‰‹ï¼Œè«‹å‘ŠçŸ¥ç”¨æˆ¶ä½ å°ˆæ³¨æ–¼å¥åº·æ•¸æ“šåˆ†ææˆ–è¨­å‚™èªªæ˜ï¼Œç„¡æ³•å›ç­”ä»¥ä¸‹å•é¡Œï¼š{state['input_message']}"
        )
        logger.info(
            f"[Router Decision] æ„åœ–è¾¨è­˜çµæœ: {state['intent']} (åŸå§‹è¨Šæ¯: {state['input_message']})"
        )
        return {"final_response": res.content}

    # --- API é€²å…¥é» ---
    async def handle_chat(self, user_id: str, message: str) -> str:
        # å–å¾—æ­·å²ç´€éŒ„
        history = self.chat_history_map.get(user_id, [])
        initial_state = {
            "user_id": user_id,
            "input_message": message,
            "messages": history + [HumanMessage(content=message)],
            "context_data": "",
        }
        try:
            # å•Ÿå‹• LangGraph ç”Ÿç”¢ç·š
            config = {"configurable": {"thread_id": user_id}}
            final_state = await self.app.ainvoke(initial_state, config=config)
            final_text = final_state["final_response"]
            intent = final_state.get("intent", "general")
            mermaid_graph = self.app.get_graph().draw_mermaid()
            if final_state.get("is_emergency"):
                mermaid_graph += "\nclass emergency_advice activeEmergencyNode"
            # æ ¼å¼åŒ–è¼¸å‡ºï¼ˆåŠ ä¸Šè¿½è¹¤è³‡è¨Šï¼Œæ–¹ä¾¿ç ”ç©¶åˆ†æï¼‰
            logger.info(
                f"\n\n-Agent è·¯ç”±è¿½è¹¤-\næ„åœ–ï¼š{final_state.get('intent')}\nç¯€é»è·¯å¾‘ï¼šRouter -> {final_state.get('intent')}_expert"
            )
            # æ›´æ–°è¨˜æ†¶é«”
            self._update_history(user_id, message, final_text)
            # æ•´ç†å›å‚³çµæ§‹
            response_data = {
                "text": final_text,
                "graph": mermaid_graph,
                "intent": intent,
            }
            logger.info(f"[Response] User: {user_id}, Intent: {intent}")
            return response_data

        except Exception as e:
            logger.error(f"Graph Execution Error: {e}", exc_info=True)
            return {
                "text": "åˆ†æéç¨‹å‡ºç¾ç•°å¸¸ï¼Œè«‹æª¢æŸ¥æ•¸æ“šæˆ–ç¨å¾Œå†è©¦ã€‚",
                "graph": "",
                "intent": "error",
            }

    def _update_history(self, user_id: str, user_msg: str, ai_msg: str):
        history = self.chat_history_map.get(user_id, [])
        # è™•ç† AI è¨Šæ¯ï¼šå¦‚æœåŒ…å«å·¨å¤§çš„ Base64 åœ–ç‰‡ï¼Œå°‡å…¶æ›¿æ›ç‚ºä½”ä½ç¬¦
        cleaned_ai_msg = re.sub(
            r"data:image/[^;]+;base64,[A-Za-z0-9+/=]+", "[åœ–è¡¨æ•¸æ“šå·²å­˜æª”]", ai_msg
        )
        history.append(HumanMessage(content=user_msg))
        history.append(AIMessage(content=cleaned_ai_msg))
        # ä¿æŒæœ€è¿‘ 10 å‰‡å°è©± (5 è¼ªå°è©±)
        self.chat_history_map[user_id] = history[-10:]
        logger.info(
            f"[Memory] User: {user_id} | æ­·å²è¨Šæ¯æ•¸: {len(self.chat_history_map[user_id])} | "
            f"AI å›è¦†æ‘˜è¦: {cleaned_ai_msg[:50].replace('\n', ' ')}..."
        )


def save_graph_image(agent_service):
    try:
        # å–å¾—ç·¨è­¯å¾Œçš„åœ–çµæ§‹ï¼Œä¸¦è½‰æ›ç‚º Mermaid æ ¼å¼çš„ PNG
        graph_image = agent_service.app.get_graph().draw_mermaid_png()

        with open("agent_workflow.png", "wb") as f:
            f.write(graph_image)
        logger.info("æµç¨‹åœ–å·²æˆåŠŸå„²å­˜ç‚º agent_workflow.png")
    except Exception as e:
        logger.error(f"ç„¡æ³•ç”¢ç”Ÿåœ–ç‰‡ï¼Œè«‹ç¢ºä¿å®‰è£äº†å¿…è¦å¥—ä»¶: {e}")
